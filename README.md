# miyuan
models

alstm1: 在rnn前面加了一层卷积层，简单的调了些参数，先试试能不能跑 \\
alstm2：正在研究，使用BahdananuAttention注意力机制的LSTM-FCN
